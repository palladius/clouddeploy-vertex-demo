{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"ur8xi4C7S06n"},"outputs":[],"source":["# Copyright 2023 Google LLC\n","#\n","# Licensed under the Apache License, Version 2.0 (the \"License\");\n","# you may not use this file except in compliance with the License.\n","# You may obtain a copy of the License at\n","#\n","#     https://www.apache.org/licenses/LICENSE-2.0\n","#\n","# Unless required by applicable law or agreed to in writing, software\n","# distributed under the License is distributed on an \"AS IS\" BASIS,\n","# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n","# See the License for the specific language governing permissions and\n","# limitations under the License."]},{"cell_type":"markdown","metadata":{"id":"JAPoU8Sm5E6e"},"source":["# Next24: ML pipelines\n","\n","{TODO: Update the links below.}\n","\n","<table align=\"left\">\n","\n","  <td>\n","    <a href=\"https://colab.research.google.com/github/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/notebook_template.ipynb\">\n","      <img src=\"https://cloud.google.com/ml-engine/images/colab-logo-32px.png\" alt=\"Colab logo\"> Run in Colab\n","    </a>\n","  </td>\n","  <td>\n","    <a href=\"https://github.com/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/notebook_template.ipynb\">\n","      <img src=\"https://cloud.google.com/ml-engine/images/github-logo-32px.png\" alt=\"GitHub logo\">\n","      View on GitHub\n","    </a>\n","  </td>\n","  <td>\n","    <a href=\"https://console.cloud.google.com/vertex-ai/workbench/deploy-notebook?download_url=https://raw.githubusercontent.com/GoogleCloudPlatform/vertex-ai-samples/main/notebooks/notebook_template.ipynb\">\n","      <img src=\"https://lh3.googleusercontent.com/UiNooY4LUgW_oTvpsNhPpQzsstV5W8F7rYgxgGBD85cWJoLmrOzhVs_ksK_vgx40SHs7jCqkTkCk=e14-rj-sc0xffffff-h130-w32\" alt=\"Vertex AI logo\">\n","      Open in Vertex AI Workbench\n","    </a>\n","  </td>                                                                                               \n","</table>"]},{"cell_type":"markdown","metadata":{"id":"24743cf4a1e1"},"source":["**_NOTE_**: This notebook has been tested in the following environment:\n","\n","* Python version = 3.9"]},{"cell_type":"markdown","metadata":{"id":"tvgnzT1CKxrO"},"source":["## Overview\n","\n","This notebook shows how to run simple Sklearn-based ML pipelines on Vertex AI Pipelines."]},{"cell_type":"markdown","metadata":{"id":"d975e698c9a4"},"source":["### Objective\n","\n","In this tutorial, you learn how to build ML pipelines interactivly.\n","\n","This tutorial uses the following Google Cloud ML services and resources:\n","\n","- Vertex AI Pipelines\n","- Cloud storage\n","\n","The steps performed include:\n","\n","- Build a data processing component\n","- Build a training component\n","- Build a model eval component\n","- Build a KFP ML pipeline"]},{"cell_type":"markdown","metadata":{"id":"08d289fa873f"},"source":["### Dataset\n","\n","The California housing dataset contains census data of houses found in a given California district in 1990.\n","\n"]},{"cell_type":"markdown","metadata":{"id":"aed92deeb4a0"},"source":["### Costs\n","\n","This tutorial uses billable components of Google Cloud:\n","\n","* Vertex AI\n","* Cloud Storage\n","\n","Learn about [Vertex AI pricing](https://cloud.google.com/vertex-ai/pricing),\n","and [Cloud Storage pricing](https://cloud.google.com/storage/pricing),\n","and use the [Pricing Calculator](https://cloud.google.com/products/calculator/) to generate a cost estimate based on your projected usage."]},{"cell_type":"markdown","metadata":{"id":"i7EUnXsZhAGF"},"source":["## Installation\n","\n","Install the following packages required to execute this notebook.\n","\n","{TODO: Suggest using the latest major GA version of each package; i.e., --upgrade}"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10793,"status":"ok","timestamp":1710149544650,"user":{"displayName":"Ivan Nardini","userId":"04192340647469915671"},"user_tz":-60},"id":"2b4ef9b72d43","outputId":"8b7b34ae-387a-44dd-a617-a8e7c7b5731b"},"outputs":[{"name":"stdout","output_type":"stream","text":["\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","daal4py 2021.3.0 requires daal==2021.2.3, which is not installed.\n","anaconda-project 0.10.1 requires ruamel-yaml, which is not installed.\n","numba 0.54.1 requires numpy<1.21,>=1.17, but you have numpy 1.22.4 which is incompatible.\n","cookiecutter 1.7.2 requires Jinja2<3.0.0, but you have jinja2 3.1.3 which is incompatible.\n","cookiecutter 1.7.2 requires MarkupSafe<2.0.0, but you have markupsafe 2.1.5 which is incompatible.\u001b[0m\n"]}],"source":["! pip3 install --upgrade --quiet numpy pandas scikit-learn xgboost kfp google-cloud-aiplatform google-cloud-pipeline-components"]},{"cell_type":"markdown","metadata":{"id":"58707a750154"},"source":["### Colab only: Uncomment the following cell to restart the kernel."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"f200f10a1da3"},"outputs":[],"source":["# import IPython\n","\n","# app = IPython.Application.instance()\n","# app.kernel.do_shutdown(True)"]},{"cell_type":"markdown","metadata":{"id":"BF1j6f9HApxa"},"source":["## Before you begin\n","\n","### Set up your Google Cloud project\n","\n","**The following steps are required, regardless of your notebook environment.**\n","\n","1. [Select or create a Google Cloud project](https://console.cloud.google.com/cloud-resource-manager). When you first create an account, you get a $300 free credit towards your compute/storage costs.\n","\n","2. [Make sure that billing is enabled for your project](https://cloud.google.com/billing/docs/how-to/modify-project).\n","\n","3. [Enable the Vertex AI API](https://console.cloud.google.com/flows/enableapi?apiid=aiplatform.googleapis.com).\n","\n","4. If you are running this notebook locally, you need to install the [Cloud SDK](https://cloud.google.com/sdk)."]},{"cell_type":"markdown","metadata":{"id":"WReHDGG5g0XY"},"source":["#### Set your project ID\n","\n","**If you don't know your project ID**, try the following:\n","* Run `gcloud config list`.\n","* Run `gcloud projects list`.\n","* See the support page: [Locate the project ID](https://support.google.com/googleapi/answer/7014113)"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2074,"status":"ok","timestamp":1710160792801,"user":{"displayName":"Ivan Nardini","userId":"04192340647469915671"},"user_tz":-60},"id":"oM1iC_MfAts1","outputId":"613ceac8-e541-4db9-bec3-1c6579fe537b"},"outputs":[{"name":"stdout","output_type":"stream","text":["Updated property [core/project].\n"]}],"source":["PROJECT_ID = \"[your-project-id]\"  # @param {type:\"string\"}\n","\n","PROJECT_ID = \"rick-and-nardy-demo\"\n","\n","# Set the project id\n","! gcloud config set project {PROJECT_ID}"]},{"cell_type":"markdown","metadata":{"id":"region"},"source":["#### Region\n","\n","You can also change the `REGION` variable used by Vertex AI. Learn more about [Vertex AI regions](https://cloud.google.com/vertex-ai/docs/general/locations)."]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":1,"status":"ok","timestamp":1710160792801,"user":{"displayName":"Ivan Nardini","userId":"04192340647469915671"},"user_tz":-60},"id":"AsE4Jy5aa99c"},"outputs":[],"source":["REGION = \"us-central1\"  # @param {type: \"string\"}"]},{"cell_type":"markdown","metadata":{"id":"sBCra4QMA2wR"},"source":["### Authenticate your Google Cloud account\n","\n","Depending on your Jupyter environment, you may have to manually authenticate. Follow the relevant instructions below."]},{"cell_type":"markdown","metadata":{"id":"74ccc9e52986"},"source":["**1. Vertex AI Workbench**\n","* Do nothing as you are already authenticated."]},{"cell_type":"markdown","metadata":{"id":"de775a3773ba"},"source":["**2. Local JupyterLab instance, uncomment and run:**"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":234,"status":"ok","timestamp":1710160797340,"user":{"displayName":"Ivan Nardini","userId":"04192340647469915671"},"user_tz":-60},"id":"254614fa0c46"},"outputs":[],"source":["# ! gcloud auth login"]},{"cell_type":"markdown","metadata":{"id":"ef21552ccea8"},"source":["**3. Colab, uncomment and run:**"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":225,"status":"ok","timestamp":1710160797890,"user":{"displayName":"Ivan Nardini","userId":"04192340647469915671"},"user_tz":-60},"id":"603adbbf0532"},"outputs":[],"source":["from google.colab import auth\n","auth.authenticate_user()"]},{"cell_type":"markdown","metadata":{"id":"f6b2ccc891ed"},"source":["**4. Service account or other**\n","* See how to grant Cloud Storage permissions to your service account at https://cloud.google.com/storage/docs/gsutil/commands/iam#ch-examples."]},{"cell_type":"markdown","metadata":{"id":"zgPO1eR3CYjk"},"source":["### Create a Cloud Storage bucket\n","\n","Create a storage bucket to store intermediate artifacts such as datasets.\n","\n","- *{Note to notebook author: For any user-provided strings that need to be unique (like bucket names or model ID's), append \"-unique\" to the end so proper testing can occur}*"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":216,"status":"ok","timestamp":1710160799843,"user":{"displayName":"Ivan Nardini","userId":"04192340647469915671"},"user_tz":-60},"id":"MzGDU7TWdts_"},"outputs":[],"source":["BUCKET_URI = f\"gs://your-bucket-name-{PROJECT_ID}-unique\"  # @param {type:\"string\"}\n","\n","BUCKET_URI = f\"gs://{PROJECT_ID}\""]},{"cell_type":"markdown","metadata":{"id":"-EcIXiGsCePi"},"source":["**Only if your bucket doesn't already exist**: Run the following cell to create your Cloud Storage bucket."]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3264,"status":"ok","timestamp":1710160803930,"user":{"displayName":"Ivan Nardini","userId":"04192340647469915671"},"user_tz":-60},"id":"NIq7R4HZCfIc","outputId":"702f0e05-9707-4528-ca08-956294ab16e6"},"outputs":[{"name":"stdout","output_type":"stream","text":["Creating gs://rick-and-nardy-demo/...\n","ServiceException: 409 A Cloud Storage bucket named 'rick-and-nardy-demo' already exists. Try another name. Bucket names must be globally unique across all Google Cloud projects, including those outside of your organization.\n"]}],"source":["! gsutil mb -l {REGION} -p {PROJECT_ID} {BUCKET_URI}"]},{"cell_type":"markdown","metadata":{"id":"960505627ddf"},"source":["### Import libraries"]},{"cell_type":"code","execution_count":181,"metadata":{"executionInfo":{"elapsed":313,"status":"ok","timestamp":1710181313351,"user":{"displayName":"Ivan Nardini","userId":"04192340647469915671"},"user_tz":-60},"id":"PyQmSRbKA8r-"},"outputs":[],"source":["import kfp\n","from kfp import dsl, compiler\n","from google.cloud import aiplatform\n","from kfp.dsl import importer_node\n","from google_cloud_pipeline_components.v1.model import ModelUploadOp, ModelGetOp\n","from google_cloud_pipeline_components.types import artifact_types"]},{"cell_type":"markdown","metadata":{"id":"Pt0FnW-b14Iv"},"source":["### Set variables"]},{"cell_type":"code","execution_count":182,"metadata":{"executionInfo":{"elapsed":1,"status":"ok","timestamp":1710181313677,"user":{"displayName":"Ivan Nardini","userId":"04192340647469915671"},"user_tz":-60},"id":"eAOcaAfI16SQ"},"outputs":[],"source":["PIPELINE_ROOT = f\"{BUCKET_URI}/california_pipeline\"\n","MODEL_PATH = f\"{PIPELINE_ROOT}/model\"\n","MODEL_NAME = \"california_reg_model\""]},{"cell_type":"markdown","metadata":{"id":"init_aip:mbsdk,all"},"source":["### Initialize Vertex AI SDK for Python\n","\n","Initialize the Vertex AI SDK for Python for your project."]},{"cell_type":"code","execution_count":183,"metadata":{"executionInfo":{"elapsed":1,"status":"ok","timestamp":1710181313917,"user":{"displayName":"Ivan Nardini","userId":"04192340647469915671"},"user_tz":-60},"id":"i0LQAYTia99d"},"outputs":[],"source":["aiplatform.init(project=PROJECT_ID, location=REGION, staging_bucket=BUCKET_URI)"]},{"cell_type":"markdown","metadata":{"id":"gXawVScmgIZx"},"source":["### Create pipeline components"]},{"cell_type":"markdown","metadata":{"id":"CqCHg01xgL43"},"source":["#### Data processing component"]},{"cell_type":"code","execution_count":184,"metadata":{"executionInfo":{"elapsed":223,"status":"ok","timestamp":1710181315114,"user":{"displayName":"Ivan Nardini","userId":"04192340647469915671"},"user_tz":-60},"id":"ksm8JP9MgRYt"},"outputs":[],"source":["@dsl.component(base_image='python:3.10', packages_to_install=[\"numpy\", \"pandas\", \"scikit-learn\"])\n","def data_preprocessing_op(processed_dataset: dsl.Output[dsl.Dataset]):\n","\n","  from pathlib import Path as p\n","  from sklearn.datasets import fetch_california_housing\n","  from sklearn.impute import SimpleImputer\n","  from sklearn.preprocessing import StandardScaler\n","  import pandas as pd\n","\n","  housing = fetch_california_housing(as_frame=True)\n","  housing_df = housing['frame']\n","  x_df = housing_df.drop('MedHouseVal', axis=1)\n","  y_df = housing_df[['MedHouseVal']]\n","  processed_x = SimpleImputer().fit_transform(x_df)\n","  processed_x = StandardScaler().fit_transform(processed_x)\n","\n","  processed_x_df = pd.DataFrame(processed_x, columns=x_df.columns)\n","  housing_df = pd.merge(processed_x_df, y_df, left_index=True, right_index=True)\n","\n","  p(processed_dataset.path).mkdir(exist_ok=True)\n","  processed_dataset_path = str(p(processed_dataset.path, \"processed_dataset.csv\"))\n","  housing_df.to_csv(processed_dataset_path, index=False)\n","  processed_dataset.path = processed_dataset_path"]},{"cell_type":"markdown","metadata":{"id":"lkim8CvR7m6G"},"source":["#### Training component"]},{"cell_type":"code","execution_count":185,"metadata":{"executionInfo":{"elapsed":1,"status":"ok","timestamp":1710181315919,"user":{"displayName":"Ivan Nardini","userId":"04192340647469915671"},"user_tz":-60},"id":"8U04t84v7m6G"},"outputs":[],"source":["@dsl.component(base_image='python:3.10', packages_to_install=[\"numpy\", \"pandas\", \"scikit-learn\", \"xgboost\"])\n","def training_op(params: dict , model_path: str, processed_dataset: dsl.Input[dsl.Dataset],\n","                trained_model: dsl.Output[dsl.Model], metrics: dsl.Output[dsl.Metrics]):\n","\n","  from pathlib import Path as p\n","  import numpy as np\n","  import pandas as pd\n","  from sklearn.model_selection import train_test_split\n","  from xgboost import XGBRegressor\n","  from sklearn.metrics import mean_squared_error\n","  import joblib\n","\n","  with open(processed_dataset.path, \"r\") as preprocessed_data:\n","      processed_df = pd.read_csv(preprocessed_data)\n","\n","  x = processed_df.drop('MedHouseVal', axis=1)\n","  y = processed_df['MedHouseVal']\n","  X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.25, random_state=0)\n","  model = XGBRegressor()\n","  if params:\n","    model = XGBRegressor(**params)\n","  model = model.fit(X_train, y_train)\n","  y_pred = model.predict(X_test)\n","  rmse = round(np.sqrt(mean_squared_error(y_test, y_pred)), 3)\n","\n","  metrics.log_metric(\"rmse\", rmse)\n","  model_path = model_path.replace('gs://', '/gcs/')\n","  p(model_path).mkdir(exist_ok=True)\n","  model_filepath = str(p(model_path, \"model.joblib\"))\n","  joblib.dump(model, model_filepath)\n","  trained_model.path = model_filepath"]},{"cell_type":"markdown","metadata":{"id":"EvFIROzNgL1G"},"source":["### Build the pipeline"]},{"cell_type":"code","execution_count":188,"metadata":{"executionInfo":{"elapsed":219,"status":"ok","timestamp":1710181347348,"user":{"displayName":"Ivan Nardini","userId":"04192340647469915671"},"user_tz":-60},"id":"PlX3TM7T1SJF"},"outputs":[],"source":["@dsl.pipeline(\n","    name=\"california-demo-pipeline\",\n",")\n","def pipeline(params: dict = None, model_path:str = None, model_name: str = \"None\"):\n","\n","    \"\"\"A demo pipeline.\"\"\"\n","\n","    preprocessing_data_task = data_preprocessing_op()\n","\n","    training_task = training_op(params=params, model_path=model_path,\n","                                processed_dataset=preprocessing_data_task.outputs['processed_dataset']).after(preprocessing_data_task)\n","\n","    with dsl.If(model_name == \"None\"):\n","\n","      model_importer_task = importer_node.importer(\n","        artifact_uri=model_path,\n","        artifact_class=artifact_types.UnmanagedContainerModel,\n","        metadata={\n","            \"containerSpec\": {\n","                \"imageUri\": \"us-docker.pkg.dev/vertex-ai/prediction/xgboost-cpu.1-7:latest\"\n","            }\n","        },\n","      ).after(training_task)\n","\n","      model_upload_op = ModelUploadOp(\n","          display_name=MODEL_NAME,\n","          unmanaged_container_model=model_importer_task.outputs[\"artifact\"],\n","          version_aliases=['v1']\n","      ).after(model_importer_task)\n","\n","    with dsl.Else():\n","\n","      model_importer_task = importer_node.importer(\n","        artifact_uri=model_path,\n","        artifact_class=artifact_types.UnmanagedContainerModel,\n","        metadata={\n","            \"containerSpec\": {\n","                \"imageUri\": \"us-docker.pkg.dev/vertex-ai/prediction/xgboost-cpu.1-7:latest\"\n","            }\n","        },\n","      ).after(training_task)\n","\n","      get_model_task = ModelGetOp(model_name=model_name).after(model_importer_task)\n","\n","      model_upload_op = ModelUploadOp(\n","          display_name=MODEL_NAME,\n","          unmanaged_container_model=model_importer_task.outputs[\"artifact\"],\n","          parent_model=get_model_task.outputs[\"model\"],\n","          version_aliases=['v2']\n","      ).after(get_model_task)"]},{"cell_type":"markdown","metadata":{"id":"ZBgJq3VbxKmJ"},"source":["### Compile the pipeline"]},{"cell_type":"code","execution_count":189,"metadata":{"executionInfo":{"elapsed":221,"status":"ok","timestamp":1710181349453,"user":{"displayName":"Ivan Nardini","userId":"04192340647469915671"},"user_tz":-60},"id":"UZsCqLLG1hED"},"outputs":[],"source":["compiler.Compiler().compile(pipeline_func=pipeline, package_path=\"pipeline.yaml\")"]},{"cell_type":"markdown","metadata":{"id":"aSeGCoAtgLvg"},"source":["### Run the pipeline for training the v1 of the model"]},{"cell_type":"code","execution_count":190,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":706},"executionInfo":{"elapsed":345659,"status":"error","timestamp":1710181704116,"user":{"displayName":"Ivan Nardini","userId":"04192340647469915671"},"user_tz":-60},"id":"fjEiNUK71x9M","outputId":"5674fd9c-5903-4576-8c5e-3ceddf43644a"},"outputs":[{"name":"stderr","output_type":"stream","text":["INFO:google.cloud.aiplatform.pipeline_jobs:Creating PipelineJob\n","INFO:google.cloud.aiplatform.pipeline_jobs:PipelineJob created. Resource name: projects/849075740253/locations/us-central1/pipelineJobs/california-demo-pipeline-20240311182238\n","INFO:google.cloud.aiplatform.pipeline_jobs:To use this PipelineJob in another session:\n","INFO:google.cloud.aiplatform.pipeline_jobs:pipeline_job = aiplatform.PipelineJob.get('projects/849075740253/locations/us-central1/pipelineJobs/california-demo-pipeline-20240311182238')\n","INFO:google.cloud.aiplatform.pipeline_jobs:View Pipeline Job:\n","https://console.cloud.google.com/vertex-ai/locations/us-central1/pipelines/runs/california-demo-pipeline-20240311182238?project=849075740253\n","INFO:google.cloud.aiplatform.pipeline_jobs:PipelineJob projects/849075740253/locations/us-central1/pipelineJobs/california-demo-pipeline-20240311182238 current state:\n","PipelineState.PIPELINE_STATE_RUNNING\n","INFO:google.cloud.aiplatform.pipeline_jobs:PipelineJob projects/849075740253/locations/us-central1/pipelineJobs/california-demo-pipeline-20240311182238 current state:\n","PipelineState.PIPELINE_STATE_RUNNING\n","INFO:google.cloud.aiplatform.pipeline_jobs:PipelineJob projects/849075740253/locations/us-central1/pipelineJobs/california-demo-pipeline-20240311182238 current state:\n","PipelineState.PIPELINE_STATE_RUNNING\n","INFO:google.cloud.aiplatform.pipeline_jobs:PipelineJob projects/849075740253/locations/us-central1/pipelineJobs/california-demo-pipeline-20240311182238 current state:\n","PipelineState.PIPELINE_STATE_RUNNING\n","INFO:google.cloud.aiplatform.pipeline_jobs:PipelineJob projects/849075740253/locations/us-central1/pipelineJobs/california-demo-pipeline-20240311182238 current state:\n","PipelineState.PIPELINE_STATE_RUNNING\n","INFO:google.cloud.aiplatform.pipeline_jobs:PipelineJob projects/849075740253/locations/us-central1/pipelineJobs/california-demo-pipeline-20240311182238 current state:\n","PipelineState.PIPELINE_STATE_RUNNING\n"]},{"ename":"RuntimeError","evalue":"Job failed with:\ncode: 9\nmessage: \"The DAG failed because some tasks failed. The failed tasks are: [training-op].; Job (project_id = rick-and-nardy-demo, job_id = 714056111304474624) is failed due to the above error.; Failed to handle the job: {project_number = 849075740253, job_id = 714056111304474624}\"\n","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-190-d33d04692bd2>\u001b[0m in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m )\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/cloud/aiplatform/pipeline_jobs.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, service_account, network, reserved_ip_ranges, sync, create_request_timeout)\u001b[0m\n\u001b[1;32m    321\u001b[0m         \u001b[0mnetwork\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnetwork\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0minitializer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglobal_config\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnetwork\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    322\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 323\u001b[0;31m         self._run(\n\u001b[0m\u001b[1;32m    324\u001b[0m             \u001b[0mservice_account\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mservice_account\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    325\u001b[0m             \u001b[0mnetwork\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnetwork\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/cloud/aiplatform/base.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    848\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    849\u001b[0m                     \u001b[0mVertexAiResourceNounWithFutureManager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 850\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    851\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    852\u001b[0m             \u001b[0;31m# callbacks to call within the Future (in same Thread)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/cloud/aiplatform/pipeline_jobs.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, service_account, network, reserved_ip_ranges, sync, create_request_timeout)\u001b[0m\n\u001b[1;32m    364\u001b[0m         )\n\u001b[1;32m    365\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 366\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_block_until_complete\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    367\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    368\u001b[0m     def submit(\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/cloud/aiplatform/pipeline_jobs.py\u001b[0m in \u001b[0;36m_block_until_complete\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    613\u001b[0m         \u001b[0;31m# JOB_STATE_FAILED or JOB_STATE_CANCELLED.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    614\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gca_resource\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_PIPELINE_ERROR_STATES\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 615\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Job failed with:\\n%s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gca_resource\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    616\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    617\u001b[0m             \u001b[0m_LOGGER\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_action_completed_against_resource\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"run\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"completed\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: Job failed with:\ncode: 9\nmessage: \"The DAG failed because some tasks failed. The failed tasks are: [training-op].; Job (project_id = rick-and-nardy-demo, job_id = 714056111304474624) is failed due to the above error.; Failed to handle the job: {project_number = 849075740253, job_id = 714056111304474624}\"\n"]}],"source":["job = aiplatform.PipelineJob(\n","    display_name=\"california-demo-pipeline\",\n","    template_path=\"pipeline.yaml\",\n","    pipeline_root=PIPELINE_ROOT,\n","    parameter_values={'model_path': MODEL_PATH},\n","    enable_caching=True\n",")\n","\n","job.run()"]},{"cell_type":"markdown","metadata":{"id":"ZJVYBK6OE-CR"},"source":["### Run the pipeline for training the v2 of the model"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":2,"status":"aborted","timestamp":1710181704117,"user":{"displayName":"Ivan Nardini","userId":"04192340647469915671"},"user_tz":-60},"id":"MZznChZdyiE8"},"outputs":[],"source":["model_list = aiplatform.Model.list(filter=f\"display_name={MODEL_NAME}\", order_by=\"create_time\")\n","model_name = model_list[0].name"]},{"cell_type":"code","execution_count":180,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":247697,"status":"ok","timestamp":1710180915143,"user":{"displayName":"Ivan Nardini","userId":"04192340647469915671"},"user_tz":-60},"id":"GB01p4cWEGN-","outputId":"79555af3-a904-42c7-a0d0-ed3983c5a0fc"},"outputs":[{"name":"stderr","output_type":"stream","text":["INFO:google.cloud.aiplatform.pipeline_jobs:Creating PipelineJob\n","INFO:google.cloud.aiplatform.pipeline_jobs:PipelineJob created. Resource name: projects/849075740253/locations/us-central1/pipelineJobs/california-demo-pipeline-20240311181107\n","INFO:google.cloud.aiplatform.pipeline_jobs:To use this PipelineJob in another session:\n","INFO:google.cloud.aiplatform.pipeline_jobs:pipeline_job = aiplatform.PipelineJob.get('projects/849075740253/locations/us-central1/pipelineJobs/california-demo-pipeline-20240311181107')\n","INFO:google.cloud.aiplatform.pipeline_jobs:View Pipeline Job:\n","https://console.cloud.google.com/vertex-ai/locations/us-central1/pipelines/runs/california-demo-pipeline-20240311181107?project=849075740253\n","INFO:google.cloud.aiplatform.pipeline_jobs:PipelineJob projects/849075740253/locations/us-central1/pipelineJobs/california-demo-pipeline-20240311181107 current state:\n","PipelineState.PIPELINE_STATE_RUNNING\n","INFO:google.cloud.aiplatform.pipeline_jobs:PipelineJob projects/849075740253/locations/us-central1/pipelineJobs/california-demo-pipeline-20240311181107 current state:\n","PipelineState.PIPELINE_STATE_RUNNING\n","INFO:google.cloud.aiplatform.pipeline_jobs:PipelineJob projects/849075740253/locations/us-central1/pipelineJobs/california-demo-pipeline-20240311181107 current state:\n","PipelineState.PIPELINE_STATE_RUNNING\n","INFO:google.cloud.aiplatform.pipeline_jobs:PipelineJob projects/849075740253/locations/us-central1/pipelineJobs/california-demo-pipeline-20240311181107 current state:\n","PipelineState.PIPELINE_STATE_RUNNING\n","INFO:google.cloud.aiplatform.pipeline_jobs:PipelineJob projects/849075740253/locations/us-central1/pipelineJobs/california-demo-pipeline-20240311181107 current state:\n","PipelineState.PIPELINE_STATE_RUNNING\n","INFO:google.cloud.aiplatform.pipeline_jobs:PipelineJob run completed. Resource name: projects/849075740253/locations/us-central1/pipelineJobs/california-demo-pipeline-20240311181107\n"]}],"source":["job = aiplatform.PipelineJob(\n","    display_name=\"california-demo-pipeline\",\n","    template_path=\"pipeline.yaml\",\n","    pipeline_root=PIPELINE_ROOT,\n","    parameter_values={'params': {'learning_rate': 0.0001,\n","                                 'n_estimators': 4000,\n","                                 'max_depth': 20,\n","                                 'random_state': 8},\n","                      'model_path': MODEL_PATH,\n","                      'model_name': model_name\n","                      },\n","    enable_caching=True\n",")\n","\n","job.run()"]},{"cell_type":"markdown","metadata":{"id":"TpV-iwP9qw9c"},"source":["## Cleaning up\n","\n","To clean up all Google Cloud resources used in this project, you can [delete the Google Cloud\n","project](https://cloud.google.com/resource-manager/docs/creating-managing-projects#shutting_down_projects) you used for the tutorial.\n","\n","Otherwise, you can delete the individual resources you created in this tutorial:\n","\n","{TODO: Include commands to delete individual resources below}"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sx_vKniMq9ZX"},"outputs":[],"source":["import os\n","\n","# Delete endpoint resource\n","# e.g. `endpoint.delete()`\n","\n","# Delete model resource\n","# e.g. `model.delete()`\n","\n","# Delete Cloud Storage objects that were created\n","delete_bucket = False\n","if delete_bucket or os.getenv(\"IS_TESTING\"):\n","    ! gsutil -m rm -r $BUCKET_URI"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.7"}},"nbformat":4,"nbformat_minor":0}
