# PIPELINE DEFINITION
# Name: california-demo-pipeline
# Description: A demo pipeline.
# Inputs:
#    model_name: str [Default: 'None']
#    model_path: str
#    params: dict
# Outputs:
#    training-op-metrics: system.Metrics
components:
  comp-condition-2:
    dag:
      tasks:
        importer:
          cachingOptions:
            enableCache: true
          componentRef:
            name: comp-importer
          inputs:
            parameters:
              uri:
                componentInputParameter: pipelinechannel--model_path
          taskInfo:
            name: importer
        model-upload:
          cachingOptions:
            enableCache: true
          componentRef:
            name: comp-model-upload
          dependentTasks:
          - importer
          inputs:
            artifacts:
              unmanaged_container_model:
                taskOutputArtifact:
                  outputArtifactKey: artifact
                  producerTask: importer
            parameters:
              display_name:
                runtimeValue:
                  constant: california_reg_model_by_ricc
              version_aliases:
                runtimeValue:
                  constant:
                  - v1
          taskInfo:
            name: model-upload
    inputDefinitions:
      parameters:
        pipelinechannel--model_name:
          parameterType: STRING
        pipelinechannel--model_path:
          parameterType: STRING
  comp-condition-3:
    dag:
      tasks:
        importer-2:
          cachingOptions:
            enableCache: true
          componentRef:
            name: comp-importer-2
          inputs:
            parameters:
              uri:
                componentInputParameter: pipelinechannel--model_path
          taskInfo:
            name: importer-2
        model-get:
          cachingOptions:
            enableCache: true
          componentRef:
            name: comp-model-get
          dependentTasks:
          - importer-2
          inputs:
            parameters:
              model_name:
                componentInputParameter: pipelinechannel--model_name
          taskInfo:
            name: model-get
        model-upload-2:
          cachingOptions:
            enableCache: true
          componentRef:
            name: comp-model-upload-2
          dependentTasks:
          - importer-2
          - model-get
          inputs:
            artifacts:
              parent_model:
                taskOutputArtifact:
                  outputArtifactKey: model
                  producerTask: model-get
              unmanaged_container_model:
                taskOutputArtifact:
                  outputArtifactKey: artifact
                  producerTask: importer-2
            parameters:
              display_name:
                runtimeValue:
                  constant: california_reg_model_by_ricc
              version_aliases:
                runtimeValue:
                  constant:
                  - v2
          taskInfo:
            name: model-upload-2
    inputDefinitions:
      parameters:
        pipelinechannel--model_name:
          parameterType: STRING
        pipelinechannel--model_path:
          parameterType: STRING
  comp-condition-branches-1:
    dag:
      tasks:
        condition-2:
          componentRef:
            name: comp-condition-2
          inputs:
            parameters:
              pipelinechannel--model_name:
                componentInputParameter: pipelinechannel--model_name
              pipelinechannel--model_path:
                componentInputParameter: pipelinechannel--model_path
          taskInfo:
            name: condition-2
          triggerPolicy:
            condition: inputs.parameter_values['pipelinechannel--model_name'] == 'None'
        condition-3:
          componentRef:
            name: comp-condition-3
          inputs:
            parameters:
              pipelinechannel--model_name:
                componentInputParameter: pipelinechannel--model_name
              pipelinechannel--model_path:
                componentInputParameter: pipelinechannel--model_path
          taskInfo:
            name: condition-3
          triggerPolicy:
            condition: '!(inputs.parameter_values[''pipelinechannel--model_name'']
              == ''None'')'
    inputDefinitions:
      parameters:
        pipelinechannel--model_name:
          parameterType: STRING
        pipelinechannel--model_path:
          parameterType: STRING
  comp-data-preprocessing-op:
    executorLabel: exec-data-preprocessing-op
    outputDefinitions:
      artifacts:
        processed_dataset:
          artifactType:
            schemaTitle: system.Dataset
            schemaVersion: 0.0.1
  comp-importer:
    executorLabel: exec-importer
    inputDefinitions:
      parameters:
        uri:
          parameterType: STRING
    outputDefinitions:
      artifacts:
        artifact:
          artifactType:
            schemaTitle: google.UnmanagedContainerModel
            schemaVersion: 0.0.1
  comp-importer-2:
    executorLabel: exec-importer-2
    inputDefinitions:
      parameters:
        uri:
          parameterType: STRING
    outputDefinitions:
      artifacts:
        artifact:
          artifactType:
            schemaTitle: google.UnmanagedContainerModel
            schemaVersion: 0.0.1
  comp-model-get:
    executorLabel: exec-model-get
    inputDefinitions:
      parameters:
        location:
          defaultValue: us-central1
          description: Location from which to get the VertexModel. Defaults to `us-central1`.
          isOptional: true
          parameterType: STRING
        model_name:
          description: 'Specify the model name in one of the following formats: {model}:
            Fetches the default model version. {model}@{model_version_id}: Fetches
            the model version specified by its ID. {model}@{model_version_alias}:
            Fetches the model version specified by its alias.'
          parameterType: STRING
        project:
          defaultValue: '{{$.pipeline_google_cloud_project_id}}'
          description: Project from which to get the VertexModel. Defaults to the
            project in which the PipelineJob is run.
          isOptional: true
          parameterType: STRING
    outputDefinitions:
      artifacts:
        model:
          artifactType:
            schemaTitle: google.VertexModel
            schemaVersion: 0.0.1
          description: Artifact of the Vertex Model.
  comp-model-upload:
    executorLabel: exec-model-upload
    inputDefinitions:
      artifacts:
        parent_model:
          artifactType:
            schemaTitle: google.VertexModel
            schemaVersion: 0.0.1
          description: An artifact of a model which to upload a new version to. Only
            specify this field when uploading a new version. [More information.](https://cloud.google.com/vertex-ai/docs/reference/rest/v1/projects.locations.models/upload#request-body)
          isOptional: true
        unmanaged_container_model:
          artifactType:
            schemaTitle: google.UnmanagedContainerModel
            schemaVersion: 0.0.1
          description: 'The unmanaged container model to be uploaded.  The Model can
            be passed from an upstream step or imported via a KFP `dsl.importer`.
            Example:

            from kfp import dsl

            from google_cloud_pipeline_components.types import artifact_types


            importer_spec = dsl.importer( artifact_uri=''gs://managed-pipeline-gcpc-e2e-test/automl-tabular/model'',
            artifact_class=artifact_types.UnmanagedContainerModel, metadata={ ''containerSpec'':
            { ''imageUri'': ''us-docker.pkg.dev/vertex-ai/automl-tabular/prediction-server:prod''
            } })'
          isOptional: true
      parameters:
        description:
          defaultValue: ''
          description: The description of the Model. [More information.](https://cloud.google.com/vertex-ai/docs/reference/rest/v1/projects.locations.models#Model)
          isOptional: true
          parameterType: STRING
        display_name:
          description: The display name of the Model. The name can be up to 128 characters
            long and can be consist of any UTF-8 characters. [More information.](https://cloud.google.com/vertex-ai/docs/reference/rest/v1/projects.locations.models#Model)
          parameterType: STRING
        encryption_spec_key_name:
          defaultValue: ''
          description: 'Customer-managed encryption key spec for a Model. If set,
            this Model and all sub-resources of this Model will be secured by this
            key.  Has the form: `projects/my-project/locations/my-location/keyRings/my-kr/cryptoKeys/my-key`.
            The key needs to be in the same region as where the compute resource is
            created.'
          isOptional: true
          parameterType: STRING
        explanation_metadata:
          defaultValue: {}
          description: Metadata describing the Model's input and output for explanation.
            Both `explanation_metadata` and `explanation_parameters` must be passed
            together when used. [More information.](https://cloud.google.com/vertex-ai/docs/reference/rest/v1/ExplanationSpec#explanationmetadata)
          isOptional: true
          parameterType: STRUCT
        explanation_parameters:
          defaultValue: {}
          description: Parameters to configure explaining for Model's predictions.  [More
            information.](https://cloud.google.com/vertex-ai/docs/reference/rest/v1/ExplanationSpec#ExplanationParameters)
          isOptional: true
          parameterType: STRUCT
        labels:
          defaultValue: {}
          description: The labels with user-defined metadata to organize your model.  Label
            keys and values can be no longer than 64 characters (Unicode codepoints),
            can only contain lowercase letters, numeric characters, underscores and
            dashes. International characters are allowed.  See https://goo.gl/xmQnxf
            for more information and examples of labels.
          isOptional: true
          parameterType: STRUCT
        location:
          defaultValue: us-central1
          description: Optional location to upload this Model to. If not set, defaults
            to `us-central1`.
          isOptional: true
          parameterType: STRING
        project:
          defaultValue: '{{$.pipeline_google_cloud_project_id}}'
          description: Project to upload this Model to. Defaults to the project in
            which the PipelineJob is run.
          isOptional: true
          parameterType: STRING
        version_aliases:
          defaultValue: []
          description: User provided version aliases so that a model version can be
            referenced via alias (i.e. `projects/{project}/locations/{location}/models/{modelId}@{version_alias}`
            instead of auto-generated version id (i.e. `projects/{project}/locations/{location}/models/{modelId}@{versionId}`).
            The format is [a-z][a-zA-Z0-9-]{0,126}[a-z0-9] to distinguish from versionId.
            A default version alias will be created for the first version of the model,
            and there must be exactly one default version alias for a model.
          isOptional: true
          parameterType: LIST
    outputDefinitions:
      artifacts:
        model:
          artifactType:
            schemaTitle: google.VertexModel
            schemaVersion: 0.0.1
          description: Artifact tracking the created Model version.
      parameters:
        gcp_resources:
          description: Serialized JSON of `gcp_resources` [proto](https://github.com/kubeflow/pipelines/tree/master/components/google-cloud/google_cloud_pipeline_components/proto)
            which tracks the upload Model's long-running operation.
          parameterType: STRING
  comp-model-upload-2:
    executorLabel: exec-model-upload-2
    inputDefinitions:
      artifacts:
        parent_model:
          artifactType:
            schemaTitle: google.VertexModel
            schemaVersion: 0.0.1
          description: An artifact of a model which to upload a new version to. Only
            specify this field when uploading a new version. [More information.](https://cloud.google.com/vertex-ai/docs/reference/rest/v1/projects.locations.models/upload#request-body)
          isOptional: true
        unmanaged_container_model:
          artifactType:
            schemaTitle: google.UnmanagedContainerModel
            schemaVersion: 0.0.1
          description: 'The unmanaged container model to be uploaded.  The Model can
            be passed from an upstream step or imported via a KFP `dsl.importer`.
            Example:

            from kfp import dsl

            from google_cloud_pipeline_components.types import artifact_types


            importer_spec = dsl.importer( artifact_uri=''gs://managed-pipeline-gcpc-e2e-test/automl-tabular/model'',
            artifact_class=artifact_types.UnmanagedContainerModel, metadata={ ''containerSpec'':
            { ''imageUri'': ''us-docker.pkg.dev/vertex-ai/automl-tabular/prediction-server:prod''
            } })'
          isOptional: true
      parameters:
        description:
          defaultValue: ''
          description: The description of the Model. [More information.](https://cloud.google.com/vertex-ai/docs/reference/rest/v1/projects.locations.models#Model)
          isOptional: true
          parameterType: STRING
        display_name:
          description: The display name of the Model. The name can be up to 128 characters
            long and can be consist of any UTF-8 characters. [More information.](https://cloud.google.com/vertex-ai/docs/reference/rest/v1/projects.locations.models#Model)
          parameterType: STRING
        encryption_spec_key_name:
          defaultValue: ''
          description: 'Customer-managed encryption key spec for a Model. If set,
            this Model and all sub-resources of this Model will be secured by this
            key.  Has the form: `projects/my-project/locations/my-location/keyRings/my-kr/cryptoKeys/my-key`.
            The key needs to be in the same region as where the compute resource is
            created.'
          isOptional: true
          parameterType: STRING
        explanation_metadata:
          defaultValue: {}
          description: Metadata describing the Model's input and output for explanation.
            Both `explanation_metadata` and `explanation_parameters` must be passed
            together when used. [More information.](https://cloud.google.com/vertex-ai/docs/reference/rest/v1/ExplanationSpec#explanationmetadata)
          isOptional: true
          parameterType: STRUCT
        explanation_parameters:
          defaultValue: {}
          description: Parameters to configure explaining for Model's predictions.  [More
            information.](https://cloud.google.com/vertex-ai/docs/reference/rest/v1/ExplanationSpec#ExplanationParameters)
          isOptional: true
          parameterType: STRUCT
        labels:
          defaultValue: {}
          description: The labels with user-defined metadata to organize your model.  Label
            keys and values can be no longer than 64 characters (Unicode codepoints),
            can only contain lowercase letters, numeric characters, underscores and
            dashes. International characters are allowed.  See https://goo.gl/xmQnxf
            for more information and examples of labels.
          isOptional: true
          parameterType: STRUCT
        location:
          defaultValue: us-central1
          description: Optional location to upload this Model to. If not set, defaults
            to `us-central1`.
          isOptional: true
          parameterType: STRING
        project:
          defaultValue: '{{$.pipeline_google_cloud_project_id}}'
          description: Project to upload this Model to. Defaults to the project in
            which the PipelineJob is run.
          isOptional: true
          parameterType: STRING
        version_aliases:
          defaultValue: []
          description: User provided version aliases so that a model version can be
            referenced via alias (i.e. `projects/{project}/locations/{location}/models/{modelId}@{version_alias}`
            instead of auto-generated version id (i.e. `projects/{project}/locations/{location}/models/{modelId}@{versionId}`).
            The format is [a-z][a-zA-Z0-9-]{0,126}[a-z0-9] to distinguish from versionId.
            A default version alias will be created for the first version of the model,
            and there must be exactly one default version alias for a model.
          isOptional: true
          parameterType: LIST
    outputDefinitions:
      artifacts:
        model:
          artifactType:
            schemaTitle: google.VertexModel
            schemaVersion: 0.0.1
          description: Artifact tracking the created Model version.
      parameters:
        gcp_resources:
          description: Serialized JSON of `gcp_resources` [proto](https://github.com/kubeflow/pipelines/tree/master/components/google-cloud/google_cloud_pipeline_components/proto)
            which tracks the upload Model's long-running operation.
          parameterType: STRING
  comp-training-op:
    executorLabel: exec-training-op
    inputDefinitions:
      artifacts:
        processed_dataset:
          artifactType:
            schemaTitle: system.Dataset
            schemaVersion: 0.0.1
      parameters:
        model_path:
          parameterType: STRING
        params:
          parameterType: STRUCT
    outputDefinitions:
      artifacts:
        metrics:
          artifactType:
            schemaTitle: system.Metrics
            schemaVersion: 0.0.1
        trained_model:
          artifactType:
            schemaTitle: system.Model
            schemaVersion: 0.0.1
deploymentSpec:
  executors:
    exec-data-preprocessing-op:
      container:
        args:
        - --executor_input
        - '{{$}}'
        - --function_to_execute
        - data_preprocessing_op
        command:
        - sh
        - -c
        - "\nif ! [ -x \"$(command -v pip)\" ]; then\n    python3 -m ensurepip ||\
          \ python3 -m ensurepip --user || apt-get install python3-pip\nfi\n\nPIP_DISABLE_PIP_VERSION_CHECK=1\
          \ python3 -m pip install --quiet --no-warn-script-location 'kfp==2.7.0'\
          \ '--no-deps' 'typing-extensions>=3.7.4,<5; python_version<\"3.9\"'  &&\
          \  python3 -m pip install --quiet --no-warn-script-location 'numpy' 'pandas'\
          \ 'scikit-learn' && \"$0\" \"$@\"\n"
        - sh
        - -ec
        - 'program_path=$(mktemp -d)


          printf "%s" "$0" > "$program_path/ephemeral_component.py"

          _KFP_RUNTIME=true python3 -m kfp.dsl.executor_main                         --component_module_path                         "$program_path/ephemeral_component.py"                         "$@"

          '
        - "\nimport kfp\nfrom kfp import dsl\nfrom kfp.dsl import *\nfrom typing import\
          \ *\n\ndef data_preprocessing_op(processed_dataset: dsl.Output[dsl.Dataset]):\n\
          \n  from pathlib import Path as p\n  from sklearn.datasets import fetch_california_housing\n\
          \  from sklearn.impute import SimpleImputer\n  from sklearn.preprocessing\
          \ import StandardScaler\n  import pandas as pd\n\n  housing = fetch_california_housing(as_frame=True)\n\
          \  housing_df = housing['frame']\n  x_df = housing_df.drop('MedHouseVal',\
          \ axis=1)\n  y_df = housing_df[['MedHouseVal']]\n  processed_x = SimpleImputer().fit_transform(x_df)\n\
          \  processed_x = StandardScaler().fit_transform(processed_x)\n\n  processed_x_df\
          \ = pd.DataFrame(processed_x, columns=x_df.columns)\n  housing_df = pd.merge(processed_x_df,\
          \ y_df, left_index=True, right_index=True)\n\n  p(processed_dataset.path).mkdir(exist_ok=True)\n\
          \  processed_dataset_path = str(p(processed_dataset.path, \"processed_dataset.csv\"\
          ))\n  housing_df.to_csv(processed_dataset_path, index=False)\n  processed_dataset.path\
          \ = processed_dataset_path\n\n"
        image: python:3.10
    exec-importer:
      importer:
        artifactUri:
          runtimeParameter: uri
        metadata:
          containerSpec:
            imageUri: us-docker.pkg.dev/vertex-ai/prediction/xgboost-cpu.1-7:latest
        typeSchema:
          schemaTitle: google.UnmanagedContainerModel
          schemaVersion: 0.0.1
    exec-importer-2:
      importer:
        artifactUri:
          runtimeParameter: uri
        metadata:
          containerSpec:
            imageUri: us-docker.pkg.dev/vertex-ai/prediction/xgboost-cpu.1-7:latest
        typeSchema:
          schemaTitle: google.UnmanagedContainerModel
          schemaVersion: 0.0.1
    exec-model-get:
      container:
        args:
        - --project
        - '{{$.inputs.parameters[''project'']}}'
        - --location
        - '{{$.inputs.parameters[''location'']}}'
        - --model_name
        - '{{$.inputs.parameters[''model_name'']}}'
        - --executor_input
        - '{{$}}'
        command:
        - python3
        - -u
        - -m
        - google_cloud_pipeline_components.container.v1.model.get_model.launcher
        image: gcr.io/ml-pipeline/google-cloud-pipeline-components:2.11.0
    exec-model-upload:
      container:
        args:
        - --type
        - UploadModel
        - --payload
        - '{"Concat": ["{", "\"display_name\": \"", "{{$.inputs.parameters[''display_name'']}}",
          "\"", ", \"description\": \"", "{{$.inputs.parameters[''description'']}}",
          "\"", ", \"explanation_spec\": {", "\"parameters\": ", "{{$.inputs.parameters[''explanation_parameters'']}}",
          ", \"metadata\": ", "{{$.inputs.parameters[''explanation_metadata'']}}",
          "}", ", \"encryption_spec\": {\"kms_key_name\":\"", "{{$.inputs.parameters[''encryption_spec_key_name'']}}",
          "\"}", ", \"version_aliases\": ", "{{$.inputs.parameters[''version_aliases'']}}",
          ", \"labels\": ", "{{$.inputs.parameters[''labels'']}}", ", \"pipeline_job\":
          \"", "projects/{{$.inputs.parameters[''project'']}}/locations/{{$.inputs.parameters[''location'']}}/pipelineJobs/{{$.pipeline_job_uuid}}",
          "\"", "}"]}'
        - --project
        - '{{$.inputs.parameters[''project'']}}'
        - --location
        - '{{$.inputs.parameters[''location'']}}'
        - --gcp_resources
        - '{{$.outputs.parameters[''gcp_resources''].output_file}}'
        - --executor_input
        - '{{$}}'
        - '{"IfPresent": {"InputName": "parent_model", "Then": ["--parent_model_name",
          "{{$.inputs.artifacts[''parent_model''].metadata[''resourceName'']}}"]}}'
        command:
        - python3
        - -u
        - -m
        - google_cloud_pipeline_components.container.v1.model.upload_model.launcher
        image: gcr.io/ml-pipeline/google-cloud-pipeline-components:2.11.0
    exec-model-upload-2:
      container:
        args:
        - --type
        - UploadModel
        - --payload
        - '{"Concat": ["{", "\"display_name\": \"", "{{$.inputs.parameters[''display_name'']}}",
          "\"", ", \"description\": \"", "{{$.inputs.parameters[''description'']}}",
          "\"", ", \"explanation_spec\": {", "\"parameters\": ", "{{$.inputs.parameters[''explanation_parameters'']}}",
          ", \"metadata\": ", "{{$.inputs.parameters[''explanation_metadata'']}}",
          "}", ", \"encryption_spec\": {\"kms_key_name\":\"", "{{$.inputs.parameters[''encryption_spec_key_name'']}}",
          "\"}", ", \"version_aliases\": ", "{{$.inputs.parameters[''version_aliases'']}}",
          ", \"labels\": ", "{{$.inputs.parameters[''labels'']}}", ", \"pipeline_job\":
          \"", "projects/{{$.inputs.parameters[''project'']}}/locations/{{$.inputs.parameters[''location'']}}/pipelineJobs/{{$.pipeline_job_uuid}}",
          "\"", "}"]}'
        - --project
        - '{{$.inputs.parameters[''project'']}}'
        - --location
        - '{{$.inputs.parameters[''location'']}}'
        - --gcp_resources
        - '{{$.outputs.parameters[''gcp_resources''].output_file}}'
        - --executor_input
        - '{{$}}'
        - '{"IfPresent": {"InputName": "parent_model", "Then": ["--parent_model_name",
          "{{$.inputs.artifacts[''parent_model''].metadata[''resourceName'']}}"]}}'
        command:
        - python3
        - -u
        - -m
        - google_cloud_pipeline_components.container.v1.model.upload_model.launcher
        image: gcr.io/ml-pipeline/google-cloud-pipeline-components:2.11.0
    exec-training-op:
      container:
        args:
        - --executor_input
        - '{{$}}'
        - --function_to_execute
        - training_op
        command:
        - sh
        - -c
        - "\nif ! [ -x \"$(command -v pip)\" ]; then\n    python3 -m ensurepip ||\
          \ python3 -m ensurepip --user || apt-get install python3-pip\nfi\n\nPIP_DISABLE_PIP_VERSION_CHECK=1\
          \ python3 -m pip install --quiet --no-warn-script-location 'kfp==2.7.0'\
          \ '--no-deps' 'typing-extensions>=3.7.4,<5; python_version<\"3.9\"'  &&\
          \  python3 -m pip install --quiet --no-warn-script-location 'numpy' 'pandas'\
          \ 'scikit-learn' 'xgboost' && \"$0\" \"$@\"\n"
        - sh
        - -ec
        - 'program_path=$(mktemp -d)


          printf "%s" "$0" > "$program_path/ephemeral_component.py"

          _KFP_RUNTIME=true python3 -m kfp.dsl.executor_main                         --component_module_path                         "$program_path/ephemeral_component.py"                         "$@"

          '
        - "\nimport kfp\nfrom kfp import dsl\nfrom kfp.dsl import *\nfrom typing import\
          \ *\n\ndef training_op(params: dict , model_path: str, processed_dataset:\
          \ dsl.Input[dsl.Dataset],\n                trained_model: dsl.Output[dsl.Model],\
          \ metrics: dsl.Output[dsl.Metrics]):\n\n  from pathlib import Path as p\n\
          \  import numpy as np\n  import pandas as pd\n  from sklearn.model_selection\
          \ import train_test_split\n  from xgboost import XGBRegressor\n  from sklearn.metrics\
          \ import mean_squared_error\n  import joblib\n\n  with open(processed_dataset.path,\
          \ \"r\") as preprocessed_data:\n      processed_df = pd.read_csv(preprocessed_data)\n\
          \n  x = processed_df.drop('MedHouseVal', axis=1)\n  y = processed_df['MedHouseVal']\n\
          \  X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.25,\
          \ random_state=0)\n  model = XGBRegressor()\n  if params:\n    model = XGBRegressor(**params)\n\
          \  model = model.fit(X_train, y_train)\n  y_pred = model.predict(X_test)\n\
          \  rmse = round(np.sqrt(mean_squared_error(y_test, y_pred)), 3)\n\n  metrics.log_metric(\"\
          rmse\", rmse)\n  model_path = model_path.replace('gs://', '/gcs/')\n  p(model_path).mkdir(exist_ok=True)\n\
          \  model_filepath = str(p(model_path, \"model.joblib\"))\n  joblib.dump(model,\
          \ model_filepath)\n  trained_model.path = model_filepath\n\n"
        image: python:3.10
pipelineInfo:
  description: A demo pipeline.
  name: california-demo-pipeline
root:
  dag:
    outputs:
      artifacts:
        training-op-metrics:
          artifactSelectors:
          - outputArtifactKey: metrics
            producerSubtask: training-op
    tasks:
      condition-branches-1:
        componentRef:
          name: comp-condition-branches-1
        dependentTasks:
        - training-op
        inputs:
          parameters:
            pipelinechannel--model_name:
              componentInputParameter: model_name
            pipelinechannel--model_path:
              componentInputParameter: model_path
        taskInfo:
          name: condition-branches-1
      data-preprocessing-op:
        cachingOptions:
          enableCache: true
        componentRef:
          name: comp-data-preprocessing-op
        taskInfo:
          name: data-preprocessing-op
      training-op:
        cachingOptions:
          enableCache: true
        componentRef:
          name: comp-training-op
        dependentTasks:
        - data-preprocessing-op
        inputs:
          artifacts:
            processed_dataset:
              taskOutputArtifact:
                outputArtifactKey: processed_dataset
                producerTask: data-preprocessing-op
          parameters:
            model_path:
              componentInputParameter: model_path
            params:
              componentInputParameter: params
        taskInfo:
          name: training-op
  inputDefinitions:
    parameters:
      model_name:
        defaultValue: None
        isOptional: true
        parameterType: STRING
      model_path:
        isOptional: true
        parameterType: STRING
      params:
        isOptional: true
        parameterType: STRUCT
  outputDefinitions:
    artifacts:
      training-op-metrics:
        artifactType:
          schemaTitle: system.Metrics
          schemaVersion: 0.0.1
schemaVersion: 2.1.0
sdkVersion: kfp-2.7.0
